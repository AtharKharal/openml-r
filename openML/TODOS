- produce ARFF and XML output files for results and inplementation. upload them to the server.

- query the server for results. IMHO we should focus on getting the data into R, not already analyzing and
visualizing it. later on we can provide convenience functions for this, but many users disagree on what
king of tool / framework they want to use. so first of all: provide data in a reasonable format (IMHO: data.frame)
example query: get all results for a task nr (e.g. 10CV on iris)

- check for every class member field, whether it can bei missing, and how this is encoded.
  Make this consistent and document it, both in R docs and the overview files rfom Dominik.

- are missing values correctly encoded in the arffs and parsed by R? 
  check that for a couple of datasets

- anneal file looks strange with regard to missing values, really read description and check

- for measures istm ust be clear whether they are for classif or regression (on opneml server)
  and how they are defined precisely

- do we really have to provide a source or binary file when uploading an implementation?
  in R this doesn't always make sense (e.g., for "standard learners" like rpart).

- completely checkl task 6 and its data, looks fishy

- why does task 7 has > 800 obs, isn t that anneal data with 798 obs?

- why does task 11 take so long to download / resample? is waveform5000 right?

- we need a possibility to get an implementation id of an existing implementation.
  in SQL, this is for example: SELECT fullName FROM implementation WHERE name = "weka.AODE"
